{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75febd47-6da1-4af8-a0cb-df68b52e2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import copy\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "from scipy.stats import median_abs_deviation as mad\n",
    "from matplotlib import pyplot as plt, colors\n",
    "\n",
    "from astropy import constants as const, units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table as Tb\n",
    "from astropy.wcs import WCS\n",
    "from astropy.convolution import convolve, convolve_fft, Gaussian1DKernel\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50d06a-dd58-4b32-b324-b7162a9d1c33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28d14c-3176-4aed-be4f-54fa9d46645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_header_clean(header, apply_version=None):\n",
    "    \n",
    "    header_new = copy.deepcopy(header)\n",
    "    \n",
    "    # version 1.2\n",
    "    apply_version_list = apply_version if apply_version is not None else [1.1, 1.2]\n",
    "    if \"Fits header cleaner\" in header_new[\"HISTORY\"]:\n",
    "        print(\"Find previous header modification, will skip for version:\")\n",
    "        for item in header_new[\"history\"][list(header_new[\"history\"]).index(\"Fits header cleaner\"):]:\n",
    "            if \"FHC: version \" in item:\n",
    "                hist_version = float(item.strip(\"FHC: version \"))\n",
    "                if hist_version in apply_version_list:\n",
    "                    print(hist_version)\n",
    "                    apply_version_list.remove(hist_version)\n",
    "    print(\"Will apply header cleaner version: %s\" % apply_version_list)\n",
    "\n",
    "    if 1.1 in apply_version_list:\n",
    "        # celestial coordinate\n",
    "        header_new.insert('CRPIX1', (\"CUNIT1\", \"deg\", ), after=True)\n",
    "        header_new.insert('CRPIX2', (\"CUNIT2\", \"deg\", ), after=True)\n",
    "        header_new[\"CTYPE1\"] = \"RA---TAN\"\n",
    "        header_new[\"CTYPE2\"] = \"DEC--TAN\"\n",
    "        header_new[\"CDELT1\"] = -header_new[\"CDELT2\"]\n",
    "        header_new.insert('INSTRUME', (\"LONPOLE\", 180.0, ), after=True)  # necessary to conform with fits standard\n",
    "        \n",
    "        # spectral axis\n",
    "        header_new[\"CTYPE3\"]  = \"FREQ\"\n",
    "        header_new.insert('CRPIX3', (\"CUNIT3\", \"MHz\", ), after=True)\n",
    "        header_new.insert('CUNIT3', (\"CNAME3\", \"FREQ-HEL\", ), after=True)\n",
    "        \n",
    "        header_new.insert('EQUINOX', (\"SPECSYS\", \"HELIOCEN\", \"Spectral reference frame\"), after=True)\n",
    "        header_new.remove(\"EPOCH\")\n",
    "        header_new[\"VELREF\"] = (258, \"1 LSR, 2 HEL, 3 OBS, +256 Radio\")\n",
    "        \n",
    "        header_new.rename_keyword(\"RESTFREQ\", \"RESTFRQ\")  # rest frequency key word should be RESTFRQ\n",
    "        header_new[\"RESTFRQ\"] = (1420.405751e6, \"Rest-frame frequency (Hz)\")\n",
    "\n",
    "        # polarization axis\n",
    "        header_new[\"CRVAL4\"] = -2  # LL and RR\n",
    "    \n",
    "        # beam information\n",
    "        header_new.insert('BMIN', (\"BPA\", 0, \"ALFALFA beam position angles\"), after=True)\n",
    "\n",
    "        # unit\n",
    "        header_new.insert('BUNIT', (\"BTYPE\", \"Intensity\", ))\n",
    "        header_new[\"BUNIT\"] = \"mJy/beam\"\n",
    "\n",
    "        if \"Fits header cleaner\" not in header_new[\"HISTORY\"]:\n",
    "            header_new.add_history(\"Fits header cleaner\")\n",
    "        header_new.add_history(\"FHC: version 1.1\")\n",
    "\n",
    "    if 1.2 in apply_version_list:\n",
    "        grid_ra, grid_dec = header_new[\"OBJECT\"].split(\"+\")\n",
    "        center_pos = SkyCoord(\"%s:%s:00 %s:00:00\" % (grid_ra[:2], grid_ra[2:], grid_dec), unit=\"hour, deg\")\n",
    "\n",
    "        header_new[\"CRVAL1\"] = center_pos.ra.deg\n",
    "        header_new[\"CRPIX1\"] = header_new[\"NAXIS1\"]/2. + 0.5\n",
    "        header_new[\"CRVAL2\"] = center_pos.dec.deg\n",
    "        header_new[\"CRPIX2\"] = header_new[\"NAXIS2\"]/2. + 0.5\n",
    "\n",
    "        header_new[\"CDELT1\"] = -1./60  # degree\n",
    "        header_new[\"CDELT2\"] = 1./60\n",
    "\n",
    "        if \"Fits header cleaner\" not in header_new[\"HISTORY\"]:\n",
    "            header_new.add_history(\"Fits header cleaner\")\n",
    "        header_new.add_history(\"FHC: version 1.2\")\n",
    "    \n",
    "    return header_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dea362-41a7-48f3-828b-3b84aa7f8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average the two polarizations together and return a fits HDU object with the same header\n",
    "def avg_pol(hdu):\n",
    "    new_data = np.nanmean(hdu.data, axis=0, keepdims=True)\n",
    "    new_header = copy.deepcopy(hdu.header)\n",
    "    new_header[\"NAXIS4\"] = 1\n",
    "    new_header[\"CRVAL4\"] = 0\n",
    "    \n",
    "    new_hdu = fits.PrimaryHDU(data=new_data, header=new_header)\n",
    "    \n",
    "    return new_hdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f7a1f-6dd6-43fd-bfcb-76597fe19fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vel(header):\n",
    "    wcs_use = WCS(header)\n",
    "    freq_arr= wcs_use.spectral.array_index_to_world(range(wcs_use.spectral.array_shape[0]))\n",
    "    \n",
    "    rest_freq = header['RESTFRQ'] * u.Hz\n",
    "    vel_arr = freq_arr.to(u.km / u.s, equivalencies=u.doppler_radio(rest_freq), \n",
    "                          doppler_rest=rest_freq, doppler_convention=\"radio\")\n",
    "\n",
    "    return vel_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a711336-6f99-474a-9acc-6505cdd319b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_gal(hdu, gal_vel=500*u.km/u.s):\n",
    "    # build vhel array\n",
    "    vel_arr = make_vel(hdu.header)\n",
    "    # compare with galactic velocity range\n",
    "    gal_mask = abs(vel_arr) < gal_vel\n",
    "\n",
    "    return gal_mask[None, :, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd349a8a-7408-46bf-b1ce-7c2df289b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_arr(hdu, mask=None):\n",
    "    mask_arr = np.ones(hdu.data.shape, dtype=float)\n",
    "    if mask is not None:\n",
    "        mask_arr[mask] = np.nan\n",
    "\n",
    "    return mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208b12e-7f54-4136-ad2b-dd1d49d4d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_weight(weight_hdu, threshold=0.75):\n",
    "    # normalize weight cube\n",
    "    weight_map_max = np.nanmax(weight_hdu.data, axis=1, keepdims=True)\n",
    "    weight_cube_norm = weight_hdu.data / weight_map_max\n",
    "    # mask by weight values\n",
    "    wt_mask = weight_cube_norm < threshold\n",
    "\n",
    "    return wt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65e60c-1087-4c3f-ba24-51a49005cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_noise(hdu, mask=None, method=\"mad\"):\n",
    "    \"\"\"\n",
    "    method: 'mad' using median_abs_deviation, or 'std' using standard deviation\n",
    "    \"\"\"\n",
    "    # initialize mask array\n",
    "    mask_arr = make_mask_arr(hdu, mask=mask)\n",
    "    # compute noise map\n",
    "    if \"mad\" in method:\n",
    "        noise_map = mad(hdu.data * mask_arr, axis=1, nan_policy=\"omit\", ) * 1.48\n",
    "    elif \"std\" in method:\n",
    "        noise_map = np.nanstd(hdu.data * mask_arr, axis=1, )\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown method value: %s.\" % method)\n",
    "    # construct hdu\n",
    "    noise_cube = np.expand_dims(noise_map, axis=1)\n",
    "    new_header = hdu.header.copy()\n",
    "    new_header[\"NAXIS3\"] = 1\n",
    "    new_hdu = fits.PrimaryHDU(data=noise_cube, header=hdu.header)\n",
    "\n",
    "    return new_hdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf3887-a16f-49ca-83bb-3719670f21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_rms(hdu, threshold=2*2.33*u.mJy/u.beam, use_map_noise=False, mask=None, method=\"mad\"):\n",
    "    \"\"\"\n",
    "    param use_map_noise: if True, map_noise will be called, and threshold * noise_map \n",
    "        will be the threshold\n",
    "    param threshold: if map_noise is False, threshold value will be the threshold \n",
    "    param method: passed to map_noise\n",
    "    \"\"\"\n",
    "    # initialize mask array\n",
    "    mask_arr = make_mask_arr(hdu, mask=mask)\n",
    "    # clip by \n",
    "    if use_map_noise:\n",
    "        noise_map = map_noise(hdu, mask=mask, method=method)\n",
    "        threshold *= noise_map.data * u.Unit(noise_map.header[\"BUNIT\"])\n",
    "    rms_mask = hdu.data * mask_arr * u.Unit(hdu.header[\"BUNIT\"]) > threshold\n",
    "\n",
    "    return rms_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fcd22-2073-47ed-9c1c-d1691621e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kern_smooth(hdu, kern, mask=None, conv_kwargs={}):\n",
    "    new_data = np.empty_like(hdu.data)\n",
    "    conv_kwargs_use = {\"normalize_kernel\": True, \n",
    "                       \"nan_treatment\": \"interpolate\", \n",
    "                       \"preserve_nan\": True}\n",
    "    conv_kwargs_use.update(conv_kwargs)\n",
    "    if np.ndim(kern) > 3:\n",
    "        kern_use = kern[0]\n",
    "    else:\n",
    "        kern_use = kern\n",
    "    for pol_idx, pol_arr in enumerate(hdu.data):\n",
    "        if mask is not None:\n",
    "            if mask.shape[0] > pol_idx:\n",
    "                mask_use = mask[0]\n",
    "            else:\n",
    "                mask_use = mask[pol_idx]\n",
    "        else:\n",
    "            mask_use = mask\n",
    "        new_data[pol_idx] = convolve_fft(\n",
    "            pol_arr, kernel=kern_use, mask=mask_use, **conv_kwargs)\n",
    "    \n",
    "    new_hdu = fits.PrimaryHDU(data=new_data, header=hdu.header)\n",
    "\n",
    "    return new_hdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8ea2a-ba94-49a0-a8ec-6531c420c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_psf(header, ch_fwhm=2, bmaj_scale=1, bmin_scale=1):\n",
    "    freq_psf = Gaussian1DKernel(ch_fwhm/2.355)\n",
    "    dec_psf = Gaussian1DKernel(abs(header[\"BMAJ\"]*bmaj_scale/header[\"CDELT2\"])/2.355)\n",
    "    ra_psf = Gaussian1DKernel(abs(header[\"BMIN\"]*bmin_scale/header[\"CDELT1\"])/2.355)\n",
    "\n",
    "    psf_arr = freq_psf.array[None, :, None, None] * \\\n",
    "                dec_psf.array[None, None, :, None] * \\\n",
    "                ra_psf.array[None, None, None, :]\n",
    "\n",
    "    return psf_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc1fc1-c4ec-4b66-a1eb-4a1c222b7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_mom(hdu, mom=0, mask=None, ):\n",
    "    # initialize mask array\n",
    "    mask_arr = make_mask_arr(hdu, mask=mask)\n",
    "\n",
    "    vel_arr = make_vel(hdu.header)\n",
    "    wt = hdu.data * u.Unit(hdu.header[\"BUNIT\"]) * \\\n",
    "        abs(np.interp(vel_arr, vel_arr[1:]-vel_arr[:-1], np.diff(vel_arr)))[None, :, None, None] * mask_arr\n",
    "    # stack\n",
    "    if mom == 0:\n",
    "        new_cube = wt\n",
    "    elif mom == 1:\n",
    "        mom0_map = map_mom(hdu, mom=0, mask=None, noise_map=None)\n",
    "        new_cube = wt * vel_arr[None, :, None, None] / \\\n",
    "        (mom0_map.data * u.Unit(mom0_map.header[\"BUNIT\"]))\n",
    "    else:\n",
    "        mom0_map = map_mom(hdu, mom=0, mask=None, noise_map=None)\n",
    "        mom1_map = map_mom(hdu, mom=1, mask=None, noise_map=None)\n",
    "        new_cube = wt * (vel_arr[None, :, None, None] - \\\n",
    "                         (mom1_map.data * u.Unit(mom1_map.header[\"BUNIT\"]))) / \\\n",
    "            (mom0_map.data * u.Unit(mom0_map.header[\"BUNIT\"]))\n",
    "        \n",
    "    new_data = np.nansum(new_cube, axis=1, keepdims=True)\n",
    "    new_header = copy.deepcopy(hdu.header)\n",
    "    new_header[\"NAXIS3\"] = 1\n",
    "    new_header[\"BUNIT\"] = new_data.unit.to_string()\n",
    "    mom_map = fits.PrimaryHDU(data=new_data.value, header=new_header)\n",
    "    \n",
    "    return mom_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ee999-9c16-4815-b3ec-0e1e233317c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppl_src_mask(hdu, ch_smooth_list=[0, 2, 4], rms_thre_list=[5, 8, 15], \n",
    "                 mask=None, method=\"mad\", min_occur=2):\n",
    "    src_mask = make_mask_arr(hdu, None) * 0\n",
    "    \n",
    "    for ch_smooth, rms_thre in zip(ch_smooth_list, rms_thre_list):\n",
    "        ch_kern = Gaussian1DKernel(ch_smooth/2.355).array[None, :, None, None]\n",
    "        conv_cube = kern_smooth(hdu, kern=ch_kern, mask=mask) if ch_smooth != 0 else hdu\n",
    "\n",
    "        rms_mask = mask_rms(conv_cube, threshold=rms_thre, use_map_noise=True, \n",
    "                            mask=mask, method=method)\n",
    "\n",
    "        # cross check pol\n",
    "        if ch_smooth != 0:\n",
    "            src_mask += kern_smooth(fits.PrimaryHDU(data=(rms_mask[0] & rms_mask[1])[None, :, :, :].astype(float), \n",
    "                                                    header=hdu.header), \n",
    "                                    kern=ch_kern/ch_kern.max(), mask=mask, conv_kwargs={\"normalize_kernel\": False}).data >= 1\n",
    "        else:\n",
    "            src_mask += (rms_mask[0] & rms_mask[1])\n",
    "\n",
    "    src_mask = src_mask >= min(min_occur, len(ch_smooth_list))\n",
    "    new_header = copy.deepcopy(hdu.header)\n",
    "    new_header[\"NAXIS3\"] = 1\n",
    "    src_mask_hdu = fits.PrimaryHDU(data=src_mask.astype(float), header=hdu.header)\n",
    "    # expand src mask by psf\n",
    "    psf_smooth = make_psf(hdu.header, ch_fwhm=2, )\n",
    "    src_exp_mask = kern_smooth(src_mask_hdu, psf_smooth, \n",
    "                               mask=mask, conv_kwargs={\"normalize_kernel\": False}).data\n",
    "    src_exp_mask = src_exp_mask > 0.01\n",
    "\n",
    "    return src_exp_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3c9ba-f04c-4370-9e3d-cd2b992e8e0d",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54243a6d-f0ad-46b8-bdf2-8734632b3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in A100 catalog\n",
    "a100_tb = Tb.read(\"https://content.cld.iop.org/journals/0004-637X/861/1/49/revision1/apjaac956t2_mrt.txt\", format=\"ascii.mrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6210d9d-f81e-4da5-82a0-565837431e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_coord_list = SkyCoord(ra=[\"%ih%im%fs\" % (rah, ram, ras) for (rah, ram, ras)\n",
    "                              in zip(a100_tb[\"HIRAh\"], a100_tb[\"HIRAm\"], a100_tb[\"HIRAs\"])], \n",
    "                          dec=[\"%s%id%im%fs\" % (design, ded, dem, des) for (design, ded, dem, des)\n",
    "                              in zip(a100_tb[\"HIDE-\"], a100_tb[\"HIDEd\"], a100_tb[\"HIDEm\"], a100_tb[\"HIDEs\"])], unit=(\"hour\", \"deg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c916a58-b860-48f8-aeb7-9346e06d500d",
   "metadata": {},
   "source": [
    "Read in the grid file, will try to read in all fits (a-d) for the input RA and Dec. We demonstrate here the 1244+33 grid which contains the NGC 4631 group, known to display large scale tidal features (e.g. [Wang+23](https://ui.adsabs.harvard.edu/abs/2023ApJ...944..102W/abstract)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323a9bc-df7f-46e1-8d94-13a77e50e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = \".\"\n",
    "grid_ra = '1244'\n",
    "grid_dec = '33'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba718c3-10d1-4d4a-83a9-2dc2d38af1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data cube\n",
    "grid_hdu_list, wgts_hdu_list = [], []\n",
    "for suffix in (\"a\", \"b\", \"c\", \"d\"):\n",
    "    fits_file = os.path.join(grid_path, '%s+%s%s_spectral.fits' % (grid_ra, grid_dec, suffix))\n",
    "    if os.path.exists(fits_file):\n",
    "        grid_hdu_list.append(fits.open(fits_file))\n",
    "        wgts_hdu_list.append(fits.open(fits_file.replace(\"_spectral.fits\", \"_spectralweights.fits\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f96bba-3a9e-4d92-bf4f-0dd6465f425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference sky coordina\n",
    "alfalfa_wcs = WCS(fits_header_clean(grid_hdu_list[0][\"PRIMARY\"].header)).celestial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517727a-eb16-4b9b-b5e7-fbb3a907f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the image size in pixels\n",
    "n_pix = 1024\n",
    "\n",
    "#Sets image size and pixel scale\n",
    "x_wid = y_wid = n_pix\n",
    "pixscale = np.sqrt(abs(np.product(np.linalg.eig(alfalfa_wcs.celestial.pixel_scale_matrix).eigenvalues*\n",
    "                                  alfalfa_wcs.celestial.pixel_shape)))/n_pix\n",
    "#Sets the coordinates of image center\n",
    "center_pos = alfalfa_wcs.celestial.array_index_to_world(\n",
    "    np.median(range(alfalfa_wcs.celestial.pixel_shape[-1])), \n",
    "    np.median(range(alfalfa_wcs.celestial.pixel_shape[-2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc6fbc-16e8-4792-9dcd-8701d6b62b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the DECaLS URL to pull both the fits and jpeg image from\n",
    "fits_url = f\"https://www.legacysurvey.org/viewer/cutout.fits?ra={center_pos.ra.deg}&dec={center_pos.dec.deg}&layer=ls-dr10&pixscale={pixscale*3600.}&width={x_wid}&height={y_wid}&bands=g\"\n",
    "fits_head = fits.getheader(fits_url)\n",
    "DECaLS_url = f\"https://www.legacysurvey.org/viewer/cutout.jpg?ra={center_pos.ra.deg}&dec={center_pos.dec.deg}&layer=ls-dr10&pixscale={pixscale*3600.}&width={x_wid}&height={y_wid}\"\n",
    "\n",
    "#Get WCS for image\n",
    "DECaLS_projection = WCS(fits_head)\n",
    "\n",
    "#Downloads and saves jpeg image\n",
    "urllib.request.urlretrieve(DECaLS_url, f'{grid_ra}+{grid_dec}_DECaLS.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9c838-9123-4673-a223-890051d83d10",
   "metadata": {},
   "source": [
    "# All grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c1d7e-39bb-4e5f-9fc0-46b0251ea6d0",
   "metadata": {},
   "source": [
    "Running the multi-scale 3d source finding. Note that it might take 10-20 minutes depending on the computational power of your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e377baa-4323-42fe-90f8-b116144ef238",
   "metadata": {},
   "outputs": [],
   "source": [
    "mom0_all = None\n",
    "for i in range(4):\n",
    "    hdu_use = grid_hdu_list[i][\"PRIMARY\"]\n",
    "    weight_hdu_use = wgts_hdu_list[i][\"PRIMARY\"]\n",
    "    hdu_use.header = fits_header_clean(hdu_use.header)\n",
    "    weight_hdu_use.header = fits_header_clean(weight_hdu_use.header)\n",
    "    gal_mask = mask_gal(hdu_use)\n",
    "    wt_mask = mask_weight(weight_hdu_use)\n",
    "    src_mask = ppl_src_mask(hdu_use, \n",
    "                            ch_smooth_list=[0,  1, 2, 4, 8, 12, 24, 36, 48, 60, ], \n",
    "                            rms_thre_list= [3.5]*10, \n",
    "                            mask=gal_mask|wt_mask, min_occur=3)\n",
    "\n",
    "    mom0_map = map_mom(hdu_use, mom=0, mask=gal_mask|wt_mask|~src_mask)\n",
    "\n",
    "    if mom0_all is None:\n",
    "        mom0_all = mom0_map\n",
    "    else:\n",
    "        mom0_all.data += mom0_map.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b9f17-b4ac-4cf9-9509-c69a9904d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ALFALFA table coordinates for image coordinates\n",
    "src_xy = DECaLS_projection.world_to_pixel(src_coord_list)\n",
    "use_flag = np.isfinite(src_xy[0]) & np.isfinite(src_xy[1]) & \\\n",
    "(src_xy[0] >= -0.5) & (src_xy[0] <= DECaLS_projection.pixel_shape[-1]-0.5) &\\\n",
    "(src_xy[1] >= -0.5) & (src_xy[1] <= DECaLS_projection.pixel_shape[-2]-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a985d-c5ff-4fa8-bf66-77a1333b7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally make the overlay\n",
    "\n",
    "#Open the DECaLS jpeg that we downloaded\n",
    "DECaLS_jpeg = Image.open(f'{grid_ra}+{grid_dec}_DECaLS.jpeg')\n",
    "\n",
    "#Set the contour levels\n",
    "min_contour = 2.355 * 2 * 5 # mJy km/s / beam\n",
    "contour_levels = min_contour*2**np.arange(9)\n",
    "\n",
    "#Make the plot\n",
    "plt.figure(figsize=[8,8], dpi=200)\n",
    "ax = plt.subplot(111,projection=DECaLS_projection)\n",
    "ax.imshow(DECaLS_jpeg)\n",
    "ax.contour(avg_pol(mom0_all).data[0, 0],colors=['w','yellow','orange','r','magenta', \"skyblue\", \"cyan\"],\n",
    "           levels=contour_levels,linewidths=0.4,transform=ax.get_transform(alfalfa_wcs))\n",
    "\n",
    "ax.scatter(src_xy[0][use_flag], src_xy[1][use_flag], marker=\"s\", s=50, facecolor=\"none\", edgecolor=\"w\")\n",
    "\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('Dec')\n",
    "\n",
    "plt.savefig('%s+%s_mom0.png' % (grid_ra, grid_dec, ))\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b84fec9-3086-4b0f-b8ff-46fd5903002e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
